{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse\n",
    "This notebook demonstrate the `tailwiz.parse` function. The purpose of the function is to extract a snippet of text from a `context` given a `prompt`. You have the option of passing in labeled data as references that the AI will use to parse the unlabeled data. If no labeled data is passed in, your data's `context` will still be parsed given `prompt`, but possibly with unexpected results.\n",
    "\n",
    "The main difference between `tailwiz.parse` and `tailwiz.generate` is that, with `tailwiz.parse`, the labels must be extracted directly from the text. By contrast, `tailwiz.generate` is able to generate labels simply given a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#######            START - Edits variables here.            #######\n",
    "\n",
    "# Instructions or question describing your task.\n",
    "prompt = 'Extract the most important phrase in determining the sentiment of the text.'\n",
    "\n",
    "# Path of data (csv) to be classified by tailwiz.\n",
    "to_parse = 'data/tweets.csv'\n",
    "# Column name of the text to be parsed by tailwiz.\n",
    "to_parse_context_col = 'text'\n",
    "\n",
    "# Path of labeled data (csv) that tailwiz learn from.\n",
    "labeled_examples = 'data/tweets-with-labels.csv'\n",
    "# Column name of the context to be learned by tailwiz.\n",
    "labeled_examples_context_col = 'text'\n",
    "# Column name of the label to be learned by tailwiz.\n",
    "labeled_examples_label_col = 'selected_text'\n",
    "\n",
    "# Path to where you want to save your results.\n",
    "save_csv = 'data/tweets-with-tailwiz-labels.csv'\n",
    "\n",
    "##################################################################\n",
    "#######   END - Leave unedited to run with example data.   #######"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example data consists of tweets (`text`), the tweet sentiment (`sentiment`, positive or negative), and an excerpt that identifies the sentiment of the tweet (`selected_text`). We have 200 labeled examples and ~3K unlabeled examples. Our goal will be to use `tailwiz` to label the 3K unlabeled examples using our 200 labeled examples as references. Providing more labeled examples will generally improve performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install `tailwiz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade tailwiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages.\n",
    "import tailwiz\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data prep\n",
    "First, we read in our example data from a .csv file using the `pandas` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled_examples = pd.read_csv(labeled_examples)\n",
    "df_to_parse = pd.read_csv(to_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 rows of labeled data.\n",
    "df_labeled_examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 rows of unlabeled data to be classified by tailwiz.\n",
    "df_to_parse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before calling tailwiz.classify with our data, we must rename our columns in accordance to `tailwiz.classify` standards.\n",
    "# The text column must be named 'text' and the label column must be named 'label'.\n",
    "df_to_parse = df_to_parse.rename(columns={to_parse_context_col: 'context'})\n",
    "df_labeled_examples = df_labeled_examples.rename(columns={labeled_examples_context_col: 'context', labeled_examples_label_col: 'label'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must create a prompt column. `tailwiz` will attempt to follow the prompt to extract the desired phrases from your context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We give all examples the same prompt.\n",
    "df_labeled_examples['prompt'] = prompt\n",
    "df_to_parse['prompt'] = prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Call `parse` function\n",
    "The next step is to call `tailwiz.parse`! We set `output_metrics` to `True` to also output an estimate of the performance of our classification job.\n",
    "\n",
    "This may take a few minutes (5-15 minutes). If this is your first time running `tailwiz.parse`, you might see some extra downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, performance_estimate = tailwiz.parse(\n",
    "    to_parse=df_to_parse[['context', 'prompt']],\n",
    "    labeled_examples=df_labeled_examples[['context', 'prompt', 'label']],\n",
    "    output_metrics=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspect and save results\n",
    "After parsing responses for our unlabeled data, we can inspect and save results.\n",
    "\n",
    "First, let's inspect the first five rows to do a quick sanity check. The new column, `tailwiz_label` contains the parsed results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print out our performance estimate to gain some additional insight to our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_estimate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only an estimate based on your labeled data. We will not know for certain how the parsing job actually performed on the unlabeled data.\n",
    "\n",
    "Finally, we can save these results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(save_csv, index=False)  # We set index to False to avoid saving the index column added by pandas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tailwiz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67d6432c23756b71b5b097123b660cae0a27a285be82db069ccf013ebbd3beba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
